{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f55ec448",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Modeling Collective Behavior in Ants\n",
    "\n",
    "### Project description:\n",
    "\n",
    "In this project, you will translate the simple ordinary differential equation (ODE) model as described in the Pratt lecture into an agent-based model. You will explore the implementation of agent-based models in Python by using the ``Mesa`` package and compare your results to those from the ODE model.\n",
    "\n",
    "### Project goals:\n",
    "\n",
    "1. Learn how to convert an ODE model to an agent-based model.\n",
    "2. Demonstrate the ability to create an agent-based model using the `Mesa` package\n",
    "\n",
    "### Project question overview:\n",
    "\n",
    "1. Write the Ant agent class to complete the agent-based model. [Question 1](#question1)\n",
    "\n",
    "\n",
    "Please run the below code to install the appropriate libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7a566e67",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import importlib\n",
    "import sys\n",
    "import pandas as pd\n",
    "import random\n",
    "from patsy import highlevel\n",
    "from mesa import Agent, Model\n",
    "from mesa.time import SimultaneousActivation\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "import math\n",
    "import sys\n",
    "from ggplot import *\n",
    "from ggplot import ggplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb9189",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Agent-based Modeling\n",
    "\n",
    "Agent-based models are used to simulate many actors or \"agents\" and their actions and interactions. These models differ from ODE models in that rather than averaging the behaviors across actors in the model, each actor is a distinct part of the model and acts according to a specified set of rules. These actors respond to both the environment and other actors within the system. Often, these models are used to simulate epidemics in which the actors represent humans and the interaction between sick individuals and healthy individuals allows for the epidemic to spread. In this project, the actors will be ants and rather than becoming infected with a disease, these ants will be influenced by recruitment via tandem running. \n",
    "\n",
    "## Forager Behavior Problem and Model\n",
    "\n",
    "### Forager Experiment\n",
    "\n",
    "As described in the \"Collective Cognition in Ant Societies\" lecture by Dr. Stephen Pratt, a simple feeder experiment can be used to demonstrate how ants collectively select a food source. In this experiment, as shown in Figure 1, two feeders are placed equidistant from a colony nest. Then, the exploration and tandem-running behaviors of ants can be observed. Ants explore the presence of the two feeders and perform tandem runs to recruit ants to the stronger feeder. Please refer to Dr. Pratt's lecture for variations and more details on this experiment. \n",
    "<a id='forager_model'></a>\n",
    "### Forager Model (ODE)\n",
    "\n",
    "As shown in Figure 2, Pratt defines a model in which the ants can be in one of three states: (1) uncommitted to a feeder; (2) committed to feeder A; and (3) committed to feeder B. In this model, every ant must be in one of these three states at any time step. To describe how ants transition between states, Pratt introduces $\\beta, \\alpha, $ and $\\lambda$ parameters. The parameters $\\alpha_A$ and $\\alpha_B$ describe the rate at which the uncommitted ants discover feeder A and feeder B respectively. In addition to independent discovery, ants can also be recruited by interacting with those ants who have committed to either feeder. This recruitment happens at the rate $\\beta_A$ for feeder A and $\\beta_B$ for feeder B. Finally, ants are not necessarily committed to a single feeder for the duration of the experiment and may return to the uncommitted state at an attrition rate of $\\lambda_A$ for feeder A and $\\lambda_B$ for feeder B.\n",
    "\n",
    "    \n",
    "<table>\n",
    "<tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/ant_feeder.png\" width=\"260\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 1: Ant feeder experiment</em>\n",
    "  </p> \n",
    "</td>\n",
    "<!-- </tr>\n",
    "</table>\n",
    "\n",
    "        \n",
    "<table>\n",
    "    <tr> -->\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"images/transition_diagram.png\" width=\"650\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 2: State transition diagram for forager behavior</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "*Image sources: Dr. Stephen Pratt*\n",
    "\n",
    "\n",
    "## Model Implementation \n",
    "\n",
    "In this project, we will use the ``Mesa`` Python package to implement our agent-based model. This project will be largely based on the introductory tutorial provided by ``Mesa`` and can be found [here](https://mesa.readthedocs.io/en/latest/tutorials/intro_tutorial.html) as well as an implementation for pheromone laying ants by Mark Goadrich which can be found on GitHub [here](https://github.com/mgoadric/ants-mesa).  \n",
    "\n",
    "### From ODE to Agent-based\n",
    "\n",
    "A ``Mesa`` simulation consists of two main classes, one for the model and the other for the agents. Each agent contains information about the state of the individual as well as how one instance of an agent may interact with another. The model class contains information such as the general parameters, and the grid the agents move on, and keeps track of the agents in their current state. \n",
    "\n",
    "The first step in converting an ODE model into an agent-based model is to establish an environment for the agents to exist in. The grid below shows the environment we will be using for this project. The grid is $50 \\times 50$ in dimension and the origin is located at the bottom left. The nest is at the location $(25,5)$ and the strong and weak feeder are at locations $(10, 40)$ and $(40, 40)$ respectively. The class that holds this model is given in the model section [here](#model).\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <p align=\"center\" style=\"padding: 10px\">\n",
    "            <img alt=\"Forwarding\" src=\"images/grid_feeders.png\" width=\"300\">\n",
    "            <br>\n",
    "            <em style=\"color: grey\">Figure 3: Environment for agent-based model</em>\n",
    "            </p>\n",
    "        </td>\n",
    "    </tr>    \n",
    "</table>\n",
    "\n",
    "## Agent Classes\n",
    "\n",
    "Now that we have established some background on where exactly these ants will be searching for food, let's take a look at the four agent classes that comprise our model. \n",
    "\n",
    "### Environment Agent\n",
    "\n",
    "The `Environment` agents will work as a placeholder to give each cell on the grid a unique identifier and position. This class is given to you below. In the model class, one ``Environment`` agent will be placed on each cell. These agents do not move or have any other properties. However, they will come in handy when the ant needs to look at which cells are available to move to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "074a1362",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Environment(Agent):\n",
    "\n",
    "    def __init__(self, unique_id, pos, model):\n",
    "        super().__init__(unique_id, model)\n",
    "        self.pos = pos\n",
    "\n",
    "    def get_pos(self):\n",
    "        return self.pos\n",
    "\n",
    "\n",
    "\n",
    "#The environment agent is placed on each cell as a place holder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df022a8",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Nest Agent\n",
    "\n",
    "The `Nest` agent records the location of the nest. The nest will be placed on the grid at location $(25,5)$. This agent class is given to you below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "624a1c9d",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Nest(Agent):\n",
    "    '''\n",
    "    The ant nest.\n",
    "    '''\n",
    "    def __init__(self, unique_id, pos, model):\n",
    "        '''\n",
    "        Records the unique_id with the super, and saves the pos.\n",
    "        '''\n",
    "        super().__init__(unique_id, model)\n",
    "        self.pos = pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a051b4",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Food Agent\n",
    "\n",
    "The food agents represent the two feeders on the map. Each agent has a unique ID, position, and amount of food. The constructor initializes the amount of food to 0 and the model class adds 100 units of food to each feeder. The `add(amount)` method adds a specified amount of food to the feeder. The `eaten()` method is used by the ants to consume one food unit from the feeder. The `any_food()` class returns a boolean indicating if there is food remaining in the feeder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fec967e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Food(Agent):\n",
    "    '''\n",
    "    A food cache for the ants, recording how much food is available.\n",
    "    '''\n",
    "    def __init__(self, unique_id, model):\n",
    "        '''\n",
    "        Records the unique_id with the super.\n",
    "        Initializes the food amount to 0.\n",
    "        '''\n",
    "        super().__init__(unique_id, model)\n",
    "        self.amount = 0\n",
    "        \n",
    "    def add(self, amount):\n",
    "        '''\n",
    "        Add the amount to the food amount\n",
    "        '''\n",
    "        self.amount += amount\n",
    "        \n",
    "    def eaten(self):\n",
    "        '''\n",
    "        Removes one food if there are any available.\n",
    "        '''\n",
    "        if self.any_food():\n",
    "            self.amount -= 1\n",
    "    \n",
    "    def any_food(self):\n",
    "        '''\n",
    "        Returns a bool to show if there is any food available\n",
    "        '''\n",
    "        return self.amount > 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94126707",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Ant Agent\n",
    "\n",
    "The final agent class defines the primary agents of the model, that is they will be moving and interacting with the other agents. As shown in the ODE model, each ant has three states as follows:\n",
    "\n",
    "- Uncommitted,\n",
    "- Committed to Feeder A,\n",
    "- and Committed to Feeder B.\n",
    "\n",
    "Note that one of the main assumptions of this model, and the ODE model, is that all ants are explorers and have the ability to recruit other ants.\n",
    "\n",
    "The ant class will consist of however many methods you decide you need to complete the requirements listed under [Question 1](#question1). You are expected to write these methods as detailed below.\n",
    "\n",
    "\n",
    "<a id='question1'></a>\n",
    "# Question 1\n",
    "\n",
    "This is the only question of the project, but it may take some time to complete accurately. It will require you to write the complete `Ant` agent class. It is strongly recommended that you refer to the pheromone laying ants model by Mark Goadrich which can be found on GitHub [here](https://github.com/mgoadric/ants-mesa). This will provide insight into how the `Mesa` package can be applied to this problem.\n",
    "\n",
    "### Constructor\n",
    "\n",
    "The constructor will meet the following criteria:\n",
    "\n",
    "- The starting position of each ant is the nest location;\n",
    "- Each ant is initialized in the \"UNCOMMITTED\" state;\n",
    "- Each ant is initialized with its tandem running flag equal to 0.\n",
    "\n",
    "### `step()` Method\n",
    "\n",
    "Since the ants will be moving with the help of a scheduler, this method will determine how each ant moves on each step depending on its current state and its tandem running flag. Figure 7 (shown below) gives a flow chart describing how the ant will move depending on its state. The red boxes with rounded edges denote states, the diamond shapes denote conditionals, and the black boxes with vertical lines denote actions.\n",
    "\n",
    "All ants begin in the uncommitted state. If an ant is UNCOMMITTED, it first checks if it is currently at a food source. If it is at a food source it commits to this food source with probability $\\alpha_A$ or $\\alpha_B$ depending on which feeder it is at. If it is not currently at a food source, or cannot commit due to the alpha parameters, it moves one cell in a random direction. In the ant commits to a food source, its state changes to either \"COMMITTED A\" or \"COMMITTED B\" depending on which feeder it is currently at. This sub-process is shown in the flow chart in Figure 4. \n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/flow_chart_pt1.png\" width=\"500\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 4: Flow chart for ant movement from initial state to committed state</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "Once an ant commits to a food source, it also attempts to uncommit with probability $\\lambda_A$ or $\\lambda_B$ for feeder A and feeder B respectively. If it stays committed, then the ant's state remains committed as before.\n",
    "\n",
    "If the ant is currently tandem running and not at a food source, it will move in the direction of the cell closest to the food source (\"food move\" in the figure). If the ant is currently tandem running and already at a food source it will eat the food, stop tandem running, and return to the committed state. This subprocess is shown in Figure 5 for only feeder A. The feeder B process is identical and shown in Figure 7.\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/flow_chart_pt2.png\" width=\"500\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 5: Flow chart for ant movement once it is committed to feeder A and tandem running.</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "Next, if the ant is committed to a food source but not tandem running, it will look for a recruit. An ant can recruit another ant if they share the same cell and the potential recruit is in the uncommitted state. If an ant finds a recruit at the current step it will recruit the ant with probability $\\beta_A$ or $\\beta_B$ for feeder A or feeder B, depending on which feeder it is committed to. To complete successful recruitment, the ant will commit the recruit to its feeder and set both itself and the recruit's tandem running flag to true. Figure 6 shows this process for feeder A, the process is the same for feeder B and can be seen in figure 7.\n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/flow_chart_pt3.png\" width=\"400\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 6: Flow chart for ant movement once committed to feeder A and not tandem running.</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "Figure 7 shows all of the subprocesses together to create the entire `step()` method. \n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/flow_chart.png\" width=\"800\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Figure 7: Flow chart for ant movement and states</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### `get_distance(pos_1, pos_2)` Function\n",
    "\n",
    "This helper function is given to you, feel free to use it (or don't) in your solution. When moving towards a food source, you will need to minimize the distance across all neighboring cells and the target food source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b330ab73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sugarscape_cg\n",
    "def get_distance(pos_1, pos_2):\n",
    "    \"\"\" \n",
    "    Get the distance between two point\n",
    "    Args:\n",
    "        pos_1, pos_2: Coordinate tuples for both points.\n",
    "    \"\"\"\n",
    "    x1, y1 = pos_1\n",
    "    x2, y2 = pos_2\n",
    "    dx = x1 - x2\n",
    "    dy = y1 - y2\n",
    "    return math.sqrt(dx ** 2 + dy ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d9d39753",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Ant(Agent):\n",
    "    '''\n",
    "    The ants wander randomly around the world in search of food. \n",
    "    If the ants find food, they commit to the feeder and attempt to recruit other ants.\n",
    "    '''\n",
    "    def __init__(self, unique_id, nest, model):\n",
    "        super().__init__(unique_id, model)  # Ensure compatibility with Mesa's Agent class\n",
    "        self.state = \"UNCOMMITTED\"  # Initial state\n",
    "        self.tandem_running = False  # Initially not tandem running\n",
    "        self.pos = nest.pos  # Start at the nest\n",
    "\n",
    "    def step(self):\n",
    "        # Ant behavior depends on its state and tandem running flag\n",
    "        if self.state == \"UNCOMMITTED\":\n",
    "            self.uncommitted_behavior()\n",
    "        elif self.state.startswith(\"COMMITTED\"):\n",
    "            self.committed_behavior()\n",
    "\n",
    "    def uncommitted_behavior(self):\n",
    "        # Check if the ant is at a food source\n",
    "        for agent in self.model.grid.get_cell_list_contents([self.pos]):\n",
    "            if isinstance(agent, Food):\n",
    "                food = agent\n",
    "                if food.any_food():\n",
    "                    # Commit to the food source with probabilities α_A or α_B\n",
    "                    if self.pos == self.model.food_locs[0] and random.random() < self.model.alpha_A:\n",
    "                        self.state = \"COMMITTED A\"\n",
    "                        return\n",
    "                    elif self.pos == self.model.food_locs[1] and random.random() < self.model.alpha_B:\n",
    "                        self.state = \"COMMITTED B\"\n",
    "                        return\n",
    "        # If not at a food source or fails to commit, move randomly\n",
    "        self.random_move()\n",
    "\n",
    "    def committed_behavior(self):\n",
    "        if self.tandem_running:\n",
    "            self.tandem_running_behavior()\n",
    "        else:\n",
    "            # Check for recruitment\n",
    "            self.recruitment_behavior()\n",
    "            # Check if the ant becomes uncommitted\n",
    "            if self.state == \"COMMITTED A\" and random.random() < self.model.lambda_A:\n",
    "                self.state = \"UNCOMMITTED\"\n",
    "            elif self.state == \"COMMITTED B\" and random.random() < self.model.lambda_B:\n",
    "                self.state = \"UNCOMMITTED\"\n",
    "\n",
    "    def tandem_running_behavior(self):\n",
    "        # Move towards the feeder\n",
    "        food_pos = self.model.food_locs[0] if self.state == \"COMMITTED A\" else self.model.food_locs[1]\n",
    "        next_pos = self.get_next_position_towards(food_pos)\n",
    "        self.model.grid.move_agent(self, next_pos)\n",
    "\n",
    "        # Check if the ant reaches the food source\n",
    "        if self.pos == food_pos:\n",
    "            for agent in self.model.grid.get_cell_list_contents([self.pos]):\n",
    "                if isinstance(agent, Food) and agent.any_food():\n",
    "                    agent.eaten()  # Consume one unit of food\n",
    "                    self.tandem_running = False  # Stop tandem running\n",
    "\n",
    "    def recruitment_behavior(self):\n",
    "        # Check for recruitable ants at the current position\n",
    "        for agent in self.model.grid.get_cell_list_contents([self.pos]):\n",
    "            if isinstance(agent, Ant) and agent.state == \"UNCOMMITTED\":\n",
    "                recruit_prob = self.model.beta_A if self.state == \"COMMITTED A\" else self.model.beta_B\n",
    "                if random.random() < recruit_prob:\n",
    "                    # Commit the recruit and start tandem running\n",
    "                    agent.state = self.state\n",
    "                    self.tandem_running = True\n",
    "                    agent.tandem_running = True\n",
    "\n",
    "    def random_move(self):\n",
    "        # Move to a random neighboring cell\n",
    "        possible_steps = self.model.grid.get_neighborhood(self.pos, moore=True, include_center=False)\n",
    "        new_position = self.random.choice(possible_steps)\n",
    "        self.model.grid.move_agent(self, new_position)\n",
    "\n",
    "    def get_next_position_towards(self, target_pos):\n",
    "        # Find the neighboring position closest to the target\n",
    "        neighbors = self.model.grid.get_neighborhood(self.pos, moore=True, include_center=False)\n",
    "        return min(neighbors, key=lambda pos: get_distance(pos, target_pos))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a16069",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## Model Class\n",
    "\n",
    "The ``Model`` class defines a grid and it keeps track of the agents through time. On each time step, the ants who are able to recruit new ants will do so depending on where they are in space and if another ant is available to be recruited. The ``DataCollector`` class is used to keep track of the agents. In particular, the data collector records the amount of food in each feeder at every time step.\n",
    "\n",
    "Additionally, the grid is an instance of the ``MultiGrid`` class. We opt to use the ``MultiGrid`` class because it allows multiple agents to occupy a single cell simultaneously. If ants were not allowed to come into contact with each other, there would be no recruitment. The definition of the model class and the relevant parameter values are set for you. The simulation ends when one feeder is completely depleted. In this case, we expect feeder A to be depleted much faster than feeder B.\n",
    "\n",
    "### Parameter Values\n",
    "\n",
    "The parameter values come from the article \"Linear Recruitment Leads to Allocation and Flexibility in Collective Foraging by Ants\" as discussed in Dr. Pratt's lecture. These values were a result of fitting the ODE model to real data. Note that in the article, one time step was equal to one minute whereas, in our simulation, one time step is equal to one second. For this reason, the parameter values were all multiplied by 60. Additionally, our simulation will have 100 ants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee4b1e",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AntModel(Model):\n",
    "    '''A model for ant foraging.'''\n",
    "    \n",
    "    def __init__(self, N=100, width=50, height=50, alpha_A = 0.0125*60, alpha_B = 0.0125*60, \n",
    "               beta_A = 0.015*60, beta_B = 0.006*60, lambda_A = 0.009, lambda_B = 0.038):\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        ##assign parameters to local variables\n",
    "        self.num_agents = N\n",
    "        self.alpha_A = alpha_A\n",
    "        self.alpha_B = alpha_B\n",
    "        self.beta_A = beta_A\n",
    "        self.beta_B = beta_B\n",
    "        self.lambda_A = lambda_A\n",
    "        self.lambda_B = lambda_B\n",
    "        \n",
    "        ##Set up of the grid and schedule:\n",
    "        \n",
    "        # Use SimultaneousActivation which simulates all the cells\n",
    "        # computing their next state simultaneously.  This needs to\n",
    "        # be done because each cell's next state depends on the current\n",
    "        # state of all its neighbors -- before they've changed.\n",
    "        self.schedule =  SimultaneousActivation(self)\n",
    "        \n",
    "        ##define 2-d grid\n",
    "        self.grid = MultiGrid(width, height, False)\n",
    "        \n",
    "        ##define starting positions for the nest and food locations\n",
    "        nest_loc = (25, 5)\n",
    "        self.food_locs = ((10, 40), (40, 40))\n",
    "        \n",
    "        self.nest = Nest(self.next_id(), nest_loc, self)\n",
    "        self.foods = []\n",
    "        self.grid.place_agent(self.nest, nest_loc)\n",
    "        self.schedule.add(self.nest)\n",
    "        \n",
    "        ##Add in the ants\n",
    "        ##create agents\n",
    "        for i in range(self.num_agents):\n",
    "            ant = Ant(self.next_id(), self.nest, self) ##instantiate agent i\n",
    "            self.grid.place_agent(ant, self.nest.pos) ##place ant in nest\n",
    "            self.schedule.add(ant) ##add ant to schedule\n",
    "            \n",
    "        ##add the food locations\n",
    "        for loc in self.food_locs:\n",
    "            food = Food(self.next_id(), self) ##instantiate food \n",
    "            food.add(100) ##give food value\n",
    "            self.grid.place_agent(food, loc) ##place food source on grid\n",
    "            self.schedule.add(food) ##add food to schedule\n",
    "            self.foods.append(food) ##add food to local list\n",
    "            \n",
    "            \n",
    "        ##add the environment cells\n",
    "        for (contents, (x, y)) in self.grid.coord_iter():\n",
    "            cell = Environment(self.next_id(), (x,y), self)\n",
    "            self.grid.place_agent(cell, (x,y))\n",
    "            self.schedule.add(cell)\n",
    "        \n",
    "        self.running = True\n",
    "        \n",
    "        ##Record the data \n",
    "        self.dc = DataCollector({\"Feeder A:\": lambda m: self.foods[0].amount,\n",
    "                               \"Feeder B:\": lambda m: self.foods[1].amount})\n",
    "        \n",
    "    def step(self):\n",
    "        '''Have the scheduler advance each cell by one step'''\n",
    "        \n",
    "        ##one step\n",
    "        self.schedule.step()\n",
    "        \n",
    "        ##collect data\n",
    "        self.dc.collect(self)\n",
    "        \n",
    "        ##stop when all of the food in a feeder is collected\n",
    "        if not self.foods[0].any_food() or not self.foods[1].any_food():\n",
    "            self.running = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad03c52",
   "metadata": {},
   "source": [
    "## Running the Model\n",
    "\n",
    "Running the model is straightforward. First, we create an instance of the model class, then we use the `run_model()` method to start the scheduler, and finally, we record the results into a data frame. This is given to you below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8cf7914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17486/2231027332.py:24: DeprecationWarning: The time module and all its Schedulers are deprecated and will be removed in Mesa 3.1. They can be replaced with AgentSet functionality. See the migration guide for details. https://mesa.readthedocs.io/latest/migration_guide.html#time-and-schedulers\n",
      "  self.schedule =  SimultaneousActivation(self)\n",
      "/tmp/ipykernel_17486/2231027332.py:33: DeprecationWarning: using model.next_id() is deprecated and will be removed in Mesa 3.1. Agents track their unique ID automatically\n",
      "  self.nest = Nest(self.next_id(), nest_loc, self)  # Correctly create a Nest agent\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ants \u001b[38;5;241m=\u001b[39m \u001b[43mAntModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#create an instance of the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m ants\u001b[38;5;241m.\u001b[39mrun_model() \u001b[38;5;66;03m#run the model\u001b[39;00m\n\u001b[1;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m ants\u001b[38;5;241m.\u001b[39mdc\u001b[38;5;241m.\u001b[39mget_model_vars_dataframe() \u001b[38;5;66;03m#store the results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[71], line 33\u001b[0m, in \u001b[0;36mAntModel.__init__\u001b[0;34m(self, N, width, height, alpha_A, alpha_B, beta_A, beta_B, lambda_A, lambda_B)\u001b[0m\n\u001b[1;32m     30\u001b[0m nest_loc \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfood_locs \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m40\u001b[39m), (\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m40\u001b[39m))\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnest \u001b[38;5;241m=\u001b[39m \u001b[43mNest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnest_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Correctly create a Nest agent\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_agents):\n\u001b[1;32m     35\u001b[0m     ant \u001b[38;5;241m=\u001b[39m Ant(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_id(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnest, \u001b[38;5;28mself\u001b[39m)  \u001b[38;5;66;03m# Correctly create Ant agents\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[67], line 9\u001b[0m, in \u001b[0;36mNest.__init__\u001b[0;34m(self, unique_id, pos, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, unique_id, pos, model):\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Records the unique_id with the super, and saves the pos.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m=\u001b[39m pos\n",
      "File \u001b[0;32m~/Documents/ASU/CSE 568 - Biocomputing/zyBooks Assignments/6 - Modeling Collective Behavior in Ants/6.1/project6.1/lib/python3.12/site-packages/mesa/agent.py:64\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new agent.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel: Model \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_id: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ids[model])\n",
      "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
     ]
    }
   ],
   "source": [
    "ants = AntModel() #create an instance of the model\n",
    "ants.run_model() #run the model\n",
    "results = ants.dc.get_model_vars_dataframe() #store the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862e1e8",
   "metadata": {},
   "source": [
    "## Visualizing the Results\n",
    "\n",
    "To visualize the results, we will first print the data frame to get an idea of the number of iterations needed to complete the simulation and to see the two feeders at the end of a run. Then, we will use the data frame to plot the amount of food in each feeder over time. \n",
    "\n",
    "Ideally, you should observe that feeder A is consumed much faster than feeder B. In this section, your results will be graded. Due to the stochastic nature of the simulation, your run must be within two standard deviations of a distribution generated over 100 runs.\n",
    "\n",
    "The code to plot the results is given below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"time\"] = np.linspace(0, len(results) - 1, len(results))\n",
    "resultsmelt = pd.melt(results, id_vars=[\"time\"], value_vars=[\"Feeder A:\",\"Feeder B:\"])\n",
    "ggplot(resultsmelt, aes(x=\"time\", y=\"value\", color=\"variable\")) \\\n",
    "+ geom_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc89e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the csv file\n",
    "import csv\n",
    "\n",
    "times_to_complete = []\n",
    "total_iterations = 50\n",
    "\n",
    "for _ in range(total_iterations + 1):\n",
    "    ants = AntModel() #create an instance of the model\n",
    "    ants.run_model() #run the model\n",
    "    results = ants.dc.get_model_vars_dataframe() #store the results\n",
    "    times_to_complete.append(results.shape[0])\n",
    "\n",
    "# don't edit the below code\n",
    "with open('/usercode/results.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(times_to_complete)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project6.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
